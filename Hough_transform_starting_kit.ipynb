{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "from __future__ import absolute_import\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import seaborn as sns\n",
    "    sns.set()\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.set_context(\"poster\")\n",
    "except ImportError as e:\n",
    "    print(\"Cannot import seaborn.\")\n",
    "    print(\"Consider installing it for nice plot !\")\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = [12.0, 9.0]\n",
    "mpl.rcParams['figure.dpi'] = 80\n",
    "mpl.rcParams['savefig.dpi'] = 100\n",
    "\n",
    "mpl.rcParams['font.size'] = 22\n",
    "mpl.rcParams['axes.labelsize'] = 18\n",
    "mpl.rcParams['ytick.labelsize'] = 18\n",
    "mpl.rcParams['xtick.labelsize'] = 18\n",
    "mpl.rcParams['legend.fontsize'] = 'large'\n",
    "mpl.rcParams['figure.titlesize'] = 'medium'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "\n",
    "## Hough Transform\n",
    "\n",
    "Consider a track pattern recognition method using the Hough Tramsform in polar system. In this system a circular track can be parametrized as follow:\n",
    "\n",
    "$$\n",
    "r = 2r_{0}Cos(\\phi - \\theta)\n",
    "$$\n",
    "\n",
    "where:\n",
    "* $r$ and $\\phi$ : are coordinates of a hit in the polar system.\n",
    "* $r_{0}$ and $\\theta$ : are coordinates of a center of a circular track in the polar system.\n",
    "\n",
    "A linear track corresponds to the $r_{0} = \\infty$.\n",
    "\n",
    "Transformation of cartesian coordinates of a hit to polar coordinates defined as:\n",
    "\n",
    "$$\n",
    "\\phi = arctan(\\frac{y}{x})\n",
    "$$\n",
    "$$\n",
    "r = \\sqrt{x^{2} + y^{2}}\n",
    "$$\n",
    "\n",
    "\n",
    "The Hough Transform converts a hit in $(r, \\phi)$ space to a curve in $(\\frac{1}{r_{0}}, \\theta)$ space of the track parameters as follow:\n",
    "\n",
    "$$\n",
    "\\frac{1}{r_{0}} = \\frac{2Cos(\\phi - \\theta)}{r}\n",
    "$$\n",
    "\n",
    "A linear track in this space represents as $(0, \\theta)$ point.\n",
    "\n",
    "\n",
    "\n",
    "however, there are 3 dimensions: x, y, z. Thus, the track pattern recognition will be performed in cylindrical coordinate systems: $\\phi$, r, z. For the simplicity (but you can create your own parameter) we suppose that for 3D tracks:\n",
    "\n",
    "$$\n",
    "\\gamma=\\frac{z}{r}=const\n",
    "$$\n",
    "\n",
    "which is true for high-PT tracks.\n",
    "\n",
    "This section demonstrates the track pattern recognition method using Hough Transfrom described above and histogramming technique. In this technique each 'hot' bin represents one recognized track as it is shown in the figure:\n",
    "\n",
    "<img src=\"pic/hough.png\" /> <br>\n",
    "\n",
    "To assign only one track lable to a hit, only bins with the highest number of hits are selected. But there is one additional requirement for the bins: these bins must not share hits. Please, look the method script for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cartesian_to_cylindrical(x, y, z):\n",
    "    \n",
    "    r = np.sqrt(x**2 + y**2)\n",
    "    phi = np.arctan2(y, x)\n",
    "    z = z\n",
    "    \n",
    "    return r, phi, z\n",
    "\n",
    "\n",
    "\n",
    "def create_hough_matrix(hit_id, x, y, z, r, phi, N):\n",
    "\n",
    "    hits_dict = {'HitID': [], 'X': [], 'Y': [], 'Z': [], 'R': [], 'Phi': [], 'Theta': []}\n",
    "    theta = list(np.linspace(-1*np.pi, 1*np.pi, N))\n",
    "    \n",
    "    for i in range(len(hit_id)):\n",
    "        \n",
    "        hits_dict['HitID'] += [hit_id[i]] * len(theta)\n",
    "        hits_dict['X'] += [x[i]] * len(theta)\n",
    "        hits_dict['Y'] += [y[i]] * len(theta)\n",
    "        hits_dict['Z'] += [z[i]] * len(theta)\n",
    "        hits_dict['R'] += [r[i]] * len(theta)\n",
    "        hits_dict['Phi'] += [phi[i]] * len(theta)\n",
    "        hits_dict['Theta'] += theta\n",
    "        \n",
    "    hough_matrix = pd.DataFrame(hits_dict)\n",
    "\n",
    "    \n",
    "    return hough_matrix\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def add_r0_inv(hough_matrix):\n",
    "    \n",
    "    hough_matrix['R0Inv'] = (2. * np.cos(hough_matrix['Phi'] - hough_matrix['Theta']) / hough_matrix['R']).values\n",
    "    \n",
    "    return hough_matrix\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def add_gamma(hough_matrix):\n",
    "    # z_hit/(np.pi - 2*(phi_hit - theta))\n",
    "    ##hough_matrix['Gamma'] = ((np.pi - 2. * (hough_matrix['Phi'] - hough_matrix['Theta'])) / hough_matrix['Z']).values\n",
    "    #hough_matrix['Gamma'] = np.ones(len(hough_matrix))\n",
    "    hough_matrix['Gamma'] = hough_matrix['Z']/hough_matrix['R']\n",
    "    \n",
    "    return hough_matrix\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def digitize_column(hough_matrix, col, N, min_val=None, max_val=None):\n",
    "    \n",
    "    x = hough_matrix[col].values\n",
    "    if min_val is not None and max_val is not None:\n",
    "        bins = np.linspace(min_val, max_val, N)\n",
    "    else:\n",
    "        bins = np.linspace(x.min(), x.max(), N)\n",
    "    bin_ids = np.digitize(x, bins)\n",
    "    hough_matrix[col+'Digi'] = bin_ids\n",
    "    \n",
    "    return hough_matrix\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def cut_min_max_bins(hough_matrix, col):\n",
    "    \n",
    "    digi = hough_matrix[col].values\n",
    "    hough_matrix = hough_matrix[(digi > digi.min()) * (digi < digi.max())]\n",
    "    \n",
    "    return hough_matrix\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def combine_digi(hough_matrix, columns):\n",
    "    \n",
    "    hough_matrix['ComboDigi'] = np.zeros(len(hough_matrix))\n",
    "    \n",
    "    for i_col, acol in enumerate(columns):\n",
    "        digi = hough_matrix[acol]\n",
    "        hough_matrix['ComboDigi'] += digi * 10**(i_col * 5)\n",
    "    \n",
    "    return hough_matrix\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def count_combo_digi(hough_matrix):\n",
    "    \n",
    "    unique, indeces, counts = np.unique(hough_matrix['ComboDigi'].values, \n",
    "                                     return_counts=True, return_inverse=True)\n",
    "    \n",
    "    hough_matrix['ComboDigiCounts'] = counts[indeces]\n",
    "    \n",
    "    return hough_matrix\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def reduce_matrix(hough_matrix, min_counts):\n",
    "    \n",
    "    return hough_matrix[hough_matrix['ComboDigiCounts'] >= min_counts].reset_index()\n",
    "\n",
    "\n",
    "\n",
    "def sorted_groups(hough_matrix):\n",
    "    \n",
    "    gb = hough_matrix.groupby('ComboDigi')\n",
    "    groups = np.array(list(gb.groups.values()))\n",
    "    group_size = [len(i) for i in groups]\n",
    "    \n",
    "    groups = groups[np.argsort(group_size)[::-1]]\n",
    "    \n",
    "    return groups\n",
    "\n",
    "\n",
    "#############################################################################################\n",
    "\n",
    "def hough_transform_clusterer(x, y, z, N_bins_theta, N_bins_r0inv, N_bins_gamma, min_hits):\n",
    "    \n",
    "    hit_id = np.arange(len(x))\n",
    "\n",
    "    r, phi, z = cartesian_to_cylindrical(x, y, z)\n",
    "    hough_matrix = create_hough_matrix(hit_id, x, y, z, r, phi, N_bins_theta)\n",
    "    \n",
    "    hough_matrix = add_r0_inv(hough_matrix)\n",
    "    hough_matrix = add_gamma(hough_matrix)\n",
    "    \n",
    "    hough_matrix = digitize_column(hough_matrix, 'Theta', N_bins_theta)\n",
    "    hough_matrix = digitize_column(hough_matrix, 'R0Inv', N_bins_r0inv, -2./100, 2./100)\n",
    "    hough_matrix = digitize_column(hough_matrix, 'Gamma', N_bins_gamma)\n",
    "    \n",
    "    hough_matrix = cut_min_max_bins(hough_matrix, 'R0InvDigi')\n",
    "    #hough_matrix = cut_min_max_bins(hough_matrix, 'GammaDigi')\n",
    "    \n",
    "    hough_matrix = combine_digi(hough_matrix, ['ThetaDigi', 'R0InvDigi', 'GammaDigi'])\n",
    "    #hough_matrix = combine_digi(hough_matrix, ['ThetaDigi', 'R0InvDigi'])\n",
    "    hough_matrix = count_combo_digi(hough_matrix)\n",
    "    hough_matrix = reduce_matrix(hough_matrix, min_hits)\n",
    "    hough_matrix\n",
    "    groups = sorted_groups(hough_matrix)\n",
    "\n",
    "\n",
    "    track_id = 0\n",
    "    track_labels = -1 * np.ones(len(hit_id))\n",
    "    used = np.zeros(len(hit_id))\n",
    "\n",
    "    matrix_hit_id = hough_matrix['HitID'].values\n",
    "\n",
    "    for gr in groups:\n",
    "\n",
    "        ids = matrix_hit_id[gr]\n",
    "        unique_hit_ids = np.unique(ids)\n",
    "        not_used_ids = unique_hit_ids[used[unique_hit_ids] == 0]\n",
    "\n",
    "        if len(not_used_ids) >= min_hits:\n",
    "\n",
    "            track_labels[not_used_ids] = track_id\n",
    "            used[not_used_ids] += 1\n",
    "            track_id +=1\n",
    "            \n",
    "    return hough_matrix, track_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tracker import BaseTracker\n",
    "\n",
    "class HoughTracker(BaseTracker):\n",
    "    def __init__(self, N_bins_theta=1000, N_bins_r0inv=200, N_bins_gamma=100, min_hits=3, verbose=1):\n",
    "        super().__init__()\n",
    "        self.N_bins_theta = N_bins_theta\n",
    "        self.N_bins_r0inv = N_bins_r0inv\n",
    "        self.N_bins_gamma = N_bins_gamma\n",
    "        self.min_hits = min_hits\n",
    "        self.verbose = verbose\n",
    "        \n",
    "    def fit_generator(self, event_generator):\n",
    "        pass\n",
    "\n",
    "    def predict_generator(self, event_generator):\n",
    "        sub_list = [self.predict_one_event(event_id, event) for event_id, event in event_generator]\n",
    "        submission = pd.concat(sub_list)\n",
    "        return submission\n",
    "    \n",
    "    def predict_one_event(self, event_id, event):\n",
    "        if self.verbose:\n",
    "            print(event_id)\n",
    "        _, labels = hough_transform_clusterer(event.x.values,\n",
    "                                              event.y.values,\n",
    "                                              event.z.values,\n",
    "                                              self.N_bins_theta,\n",
    "                                              self.N_bins_r0inv,\n",
    "                                              self.N_bins_gamma,\n",
    "                                              self.min_hits,)\n",
    "        sub = pd.DataFrame(data=np.column_stack((event.hit_id.values, labels)),\n",
    "                                  columns=[\"hit_id\", \"track_id\"]).astype(int)\n",
    "        sub['event_id'] = event_id\n",
    "        return sub\n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: impossible d'accéder à '/data/titanic_3/user/vestrade/seattle_trackml/': Aucun fichier ou dossier de ce type\r\n"
     ]
    }
   ],
   "source": [
    "!ls /data/titanic_3/user/vestrade/seattle_trackml/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Tracking on the training set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_hit_generator\n",
    "\n",
    "data_path = \"./public_data/training/\"\n",
    "event_generator = load_hit_generator(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tracker import ParallelPredictTracker\n",
    "base_tracker = HoughTracker(verbose=1)\n",
    "tracker = ParallelPredictTracker(base_tracker, n_jobs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Next cell will require some time to compute !**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n"
     ]
    }
   ],
   "source": [
    "submission = tracker.predict_generator(event_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = pd.read_csv(\"./public_data/training/solution.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from score import compute_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "score_mean, score_std, n_purity_reco, n_purity_truth = compute_score(submission, solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score mean:   0.001707\n",
      "score stddev: 0.015229\n",
      "purity_reco: 911\n",
      "purity_truth: 186\n"
     ]
    }
   ],
   "source": [
    "print('score mean:   {:f}'.format(score_mean))\n",
    "print('score stddev: {:f}'.format(score_std))\n",
    "print('purity_reco: {:d}'.format(n_purity_reco))\n",
    "print('purity_truth: {:d}'.format(n_purity_truth))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2109 predicted particles\n",
      "21866 true particles\n"
     ]
    }
   ],
   "source": [
    "print(len(submission['track_id'].unique()), 'predicted particles')\n",
    "print(len(solution['particle_id'].unique()), 'true particles')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80625 rejected hits\n",
      "0 rejected hits\n"
     ]
    }
   ],
   "source": [
    "print((submission['track_id'] == -1).sum(), 'rejected hits')\n",
    "print((solution['particle_id'] == -1).sum(), 'rejected hits')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./public_data/validation/\"\n",
    "event_generator = load_hit_generator(data_path)\n",
    "submission = tracker.predict_generator(event_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('./submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now just zip the file (**ONLY THE csv FILE ! NOT THE DIRECTORY**) and you can submit it to codalab.\n",
    "\n",
    "The submission file has to be name \"submission.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
